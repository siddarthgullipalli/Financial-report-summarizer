{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Existing ChromaDB Embeddings\n",
    "\n",
    "This notebook shows how to retrieve and use your existing ChromaDB embeddings in a new notebook.\n",
    "\n",
    "**Prerequisites:** You must have already created the ChromaDB database using `GENAI_PROJECT_CHROMADB.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages if needed\n",
    "!pip install -q chromadb==0.4.18\n",
    "!pip install -q sentence-transformers==2.2.2\n",
    "!pip install -q openai==1.12.0\n",
    "\n",
    "print(\"‚úÖ Packages installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "\n",
    "print(\"‚úÖ Libraries imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Connect to Existing ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the SAME directory where you created the database\n",
    "persist_directory = os.path.expanduser(\"~/FinancialAI/chromadb\")\n",
    "\n",
    "print(f\"üìÅ Connecting to ChromaDB at: {persist_directory}\")\n",
    "\n",
    "# Initialize ChromaDB client\n",
    "chroma_client = chromadb.PersistentClient(path=persist_directory)\n",
    "\n",
    "# Get the existing collection (don't create a new one!)\n",
    "collection = chroma_client.get_collection(name=\"financial_filings\")\n",
    "\n",
    "print(f\"‚úÖ Connected to collection: {collection.name}\")\n",
    "print(f\"üìä Total documents in collection: {collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Load the Same Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Use the SAME model you used to create embeddings\n",
    "print(\"üì• Loading FinBERT model...\")\n",
    "embedder = SentenceTransformer(\"ProsusAI/finbert\")\n",
    "\n",
    "print(f\"‚úÖ Model loaded!\")\n",
    "print(f\"üìê Embedding dimension: {embedder.get_sentence_embedding_dimension()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Retrieve All Documents (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all documents from the collection\n",
    "all_data = collection.get()\n",
    "\n",
    "print(f\"üìö Retrieved Data:\")\n",
    "print(f\"   Documents: {len(all_data['documents'])}\")\n",
    "print(f\"   IDs: {len(all_data['ids'])}\")\n",
    "print(f\"   Metadata: {len(all_data['metadatas'])}\")\n",
    "\n",
    "# Show first document as example\n",
    "if len(all_data['documents']) > 0:\n",
    "    print(f\"\\nüìÑ Example Document:\")\n",
    "    print(f\"   ID: {all_data['ids'][0]}\")\n",
    "    print(f\"   Metadata: {all_data['metadatas'][0]}\")\n",
    "    print(f\"   Text (first 200 chars): {all_data['documents'][0][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Search with Semantic Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Search for relevant documents\n",
    "query = \"What are the main revenue sources?\"\n",
    "\n",
    "print(f\"üîç Searching for: '{query}'\\n\")\n",
    "\n",
    "# Generate embedding for the query\n",
    "query_embedding = embedder.encode([query], device='cuda')\n",
    "\n",
    "# Search ChromaDB\n",
    "results = collection.query(\n",
    "    query_embeddings=query_embedding.tolist(),\n",
    "    n_results=5  # Get top 5 results\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(f\"üìä Found {len(results['documents'][0])} relevant documents:\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, (doc, metadata, distance) in enumerate(zip(\n",
    "    results['documents'][0],\n",
    "    results['metadatas'][0],\n",
    "    results['distances'][0]\n",
    "), 1):\n",
    "    print(f\"\\nResult {i}:\")\n",
    "    print(f\"Company: {metadata.get('company', 'N/A')}\")\n",
    "    print(f\"Section: {metadata.get('section', 'N/A')}\")\n",
    "    print(f\"Year: {metadata.get('year', 'N/A')}\")\n",
    "    print(f\"Distance: {distance:.4f}\")\n",
    "    print(f\"Text: {doc[:300]}...\")\n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Filter by Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Search only in specific company or section\n",
    "query = \"What are the risk factors?\"\n",
    "\n",
    "print(f\"üîç Searching with metadata filter: '{query}'\\n\")\n",
    "\n",
    "query_embedding = embedder.encode([query], device='cuda')\n",
    "\n",
    "# Search with metadata filter\n",
    "results = collection.query(\n",
    "    query_embeddings=query_embedding.tolist(),\n",
    "    n_results=5,\n",
    "    where={\"section\": \"Risk Factors\"}  # Filter by section\n",
    "    # Other filter examples:\n",
    "    # where={\"company\": \"APPLE INC\"}\n",
    "    # where={\"year\": \"2023\"}\n",
    "    # where={\"source\": \"user_upload\"}\n",
    ")\n",
    "\n",
    "print(f\"üìä Found {len(results['documents'][0])} documents from Risk Factors section\\n\")\n",
    "\n",
    "for i, (doc, metadata) in enumerate(zip(\n",
    "    results['documents'][0],\n",
    "    results['metadatas'][0]\n",
    "), 1):\n",
    "    print(f\"\\n{i}. {metadata.get('company', 'N/A')} ({metadata.get('year', 'N/A')})\")\n",
    "    print(f\"   {doc[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Get Specific Documents by ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you know specific document IDs\n",
    "# First, let's see what IDs exist\n",
    "all_data = collection.get(limit=10)  # Get first 10 IDs\n",
    "\n",
    "print(\"üìã First 10 Document IDs:\")\n",
    "for i, doc_id in enumerate(all_data['ids'], 1):\n",
    "    print(f\"   {i}. {doc_id}\")\n",
    "\n",
    "# Retrieve specific documents by ID\n",
    "if len(all_data['ids']) > 0:\n",
    "    specific_ids = all_data['ids'][:3]  # Get first 3\n",
    "    \n",
    "    specific_docs = collection.get(ids=specific_ids)\n",
    "    \n",
    "    print(f\"\\nüìÑ Retrieved {len(specific_docs['documents'])} specific documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: View Collection Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get comprehensive statistics\n",
    "all_data = collection.get()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"   CHROMADB COLLECTION STATISTICS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nTotal Documents: {collection.count()}\")\n",
    "\n",
    "# Analyze metadata\n",
    "if all_data['metadatas']:\n",
    "    companies = set(m.get('company', 'Unknown') for m in all_data['metadatas'])\n",
    "    sections = set(m.get('section', 'Unknown') for m in all_data['metadatas'])\n",
    "    years = set(m.get('year', 'Unknown') for m in all_data['metadatas'])\n",
    "    sources = set(m.get('source', 'Unknown') for m in all_data['metadatas'])\n",
    "    \n",
    "    print(f\"\\nUnique Companies: {len(companies)}\")\n",
    "    print(f\"Unique Sections: {len(sections)}\")\n",
    "    print(f\"Unique Years: {len(years)}\")\n",
    "    print(f\"Sources: {', '.join(sources)}\")\n",
    "    \n",
    "    print(f\"\\nCompanies in database:\")\n",
    "    for company in sorted(companies)[:20]:  # Show first 20\n",
    "        count = sum(1 for m in all_data['metadatas'] if m.get('company') == company)\n",
    "        print(f\"   ‚Ä¢ {company}: {count} chunks\")\n",
    "    \n",
    "    if len(companies) > 20:\n",
    "        print(f\"   ... and {len(companies) - 20} more companies\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Ask Questions with OpenAI (RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your OpenAI API key\n",
    "os.environ['OPENAI_API_KEY'] = 'your-api-key-here'  # Replace with your key\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "def ask_question(question, top_k=5):\n",
    "    \"\"\"\n",
    "    Ask a question using RAG (Retrieval-Augmented Generation)\n",
    "    \"\"\"\n",
    "    print(f\"‚ùì Question: {question}\\n\")\n",
    "    print(\"üîç Searching for relevant context...\\n\")\n",
    "    \n",
    "    # Generate query embedding\n",
    "    query_embedding = embedder.encode([question], device='cuda')\n",
    "    \n",
    "    # Search ChromaDB\n",
    "    results = collection.query(\n",
    "        query_embeddings=query_embedding.tolist(),\n",
    "        n_results=top_k\n",
    "    )\n",
    "    \n",
    "    # Build context\n",
    "    context_parts = []\n",
    "    for i, (doc, metadata) in enumerate(zip(\n",
    "        results['documents'][0],\n",
    "        results['metadatas'][0]\n",
    "    ), 1):\n",
    "        source = f\"{metadata.get('company', 'Unknown')} | {metadata.get('section', 'Unknown')}\"\n",
    "        context_parts.append(f\"[Source {i}: {source}]\\n{doc}\")\n",
    "    \n",
    "    context = \"\\n\\n---\\n\\n\".join(context_parts)\n",
    "    \n",
    "    # Generate answer\n",
    "    prompt = f\"\"\"You are an expert financial analyst.\n",
    "\n",
    "Context from financial documents:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Instructions:\n",
    "1. Answer ONLY using information from the context\n",
    "2. Cite which company and section you're using\n",
    "3. Be specific with numbers and metrics\n",
    "4. If information is not in context, say so\n",
    "\n",
    "Your analysis:\"\"\"\n",
    "    \n",
    "    print(\"üí≠ Generating answer...\\n\")\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert financial analyst.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "        max_tokens=800\n",
    "    )\n",
    "    \n",
    "    answer = response.choices[0].message.content\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"üìä ANSWER\")\n",
    "    print(\"=\" * 70)\n",
    "    print(answer)\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    return answer\n",
    "\n",
    "# Example usage\n",
    "# answer = ask_question(\"What are the main business activities of these companies?\")\n",
    "# answer = ask_question(\"Compare the revenue growth strategies\")\n",
    "# answer = ask_question(\"What are the key risk factors mentioned?\")\n",
    "\n",
    "print(\"‚úÖ RAG function ready! Use: ask_question('your question')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Reference: Common Operations\n",
    "\n",
    "```python\n",
    "# 1. Get all documents\n",
    "all_data = collection.get()\n",
    "\n",
    "# 2. Get limited documents\n",
    "limited_data = collection.get(limit=100)\n",
    "\n",
    "# 3. Get specific documents by ID\n",
    "specific = collection.get(ids=[\"id1\", \"id2\"])\n",
    "\n",
    "# 4. Semantic search\n",
    "embedding = embedder.encode([\"your query\"])\n",
    "results = collection.query(\n",
    "    query_embeddings=embedding.tolist(),\n",
    "    n_results=5\n",
    ")\n",
    "\n",
    "# 5. Search with metadata filter\n",
    "results = collection.query(\n",
    "    query_embeddings=embedding.tolist(),\n",
    "    n_results=5,\n",
    "    where={\"company\": \"APPLE INC\"}\n",
    ")\n",
    "\n",
    "# 6. Count documents\n",
    "total = collection.count()\n",
    "\n",
    "# 7. Delete documents by ID\n",
    "collection.delete(ids=[\"id_to_delete\"])\n",
    "\n",
    "# 8. Update documents\n",
    "collection.update(\n",
    "    ids=[\"id1\"],\n",
    "    documents=[\"new text\"],\n",
    "    metadatas=[{\"key\": \"value\"}]\n",
    ")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
